{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Colorization\n",
    "(under development on Google Colab)\n",
    "\n",
    "![Colorizing](https://camo.githubusercontent.com/901b86daa84139fdd997127f9287b9fdbeaaa7fd/68747470733a2f2f676f6f2e676c2f697a746e5932)\n",
    "\n",
    "To contribute to the project please go through the CONTRIBUTING.md in the root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6247,
     "status": "ok",
     "timestamp": 1544074092575,
     "user": {
      "displayName": "Shravankumar Shetty",
      "photoUrl": "https://lh3.googleusercontent.com/-jCxID2zpAz4/AAAAAAAAAAI/AAAAAAAAEKw/RMlX-iUrE1M/s64/photo.jpg",
      "userId": "00357225673176527270"
     },
     "user_tz": -330
    },
    "id": "cNNkUxCWsto3",
    "outputId": "52859755-5af8-4d2e-a3af-9968f951def1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/content/drive', force_remount = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5132,
     "status": "ok",
     "timestamp": 1544074099116,
     "user": {
      "displayName": "Shravankumar Shetty",
      "photoUrl": "https://lh3.googleusercontent.com/-jCxID2zpAz4/AAAAAAAAAAI/AAAAAAAAEKw/RMlX-iUrE1M/s64/photo.jpg",
      "userId": "00357225673176527270"
     },
     "user_tz": -330
    },
    "id": "zeFMOyPWgqdQ",
    "outputId": "3f4692de-a3b2-4659-bf84-4ba4f8eefaaf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "\n",
    "import keras\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.preprocessing import image\n",
    "from keras.engine import Layer\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate, Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import RepeatVector, Permute\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5I_cq17GmhoR"
   },
   "outputs": [],
   "source": [
    "# Get images\n",
    "# Change to '/data/images/Train/' to use all the 10k images\n",
    "IMG_LOCATION = '/content/drive/My Drive/Colab_Notebooks/Drishti/Dataset/Train/'\n",
    "X = []\n",
    "COUNT = 0\n",
    "for filename in os.listdir(IMG_LOCATION):\n",
    "    X.append(img_to_array(load_img(IMG_LOCATION+filename)))\n",
    "    COUNT = COUNT + 1\n",
    "    if(COUNT == 3000):\n",
    "      break\n",
    "X = np.array(X, dtype=float)\n",
    "Xtrain = 1.0/255*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T-9BE0rS-XhS"
   },
   "outputs": [],
   "source": [
    "#Load weights\n",
    "inception = InceptionResNetV2(weights=None, include_top=True)\n",
    "inception.load_weights(IMG_LOCATION + '../../Dataset/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "inception.graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dlwB0OGSgxcL"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "embed_input = Input(shape=(1000,))\n",
    "\n",
    "#Encoder\n",
    "encoder_input = Input(shape=(256, 256, 1,))\n",
    "encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_input)\n",
    "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
    "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "\n",
    "#Fusion\n",
    "fusion_output = RepeatVector(32 * 32)(embed_input) \n",
    "fusion_output = Reshape(([32, 32, 1000]))(fusion_output)\n",
    "fusion_output = concatenate([encoder_output, fusion_output], axis=3) \n",
    "fusion_output = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion_output) \n",
    "\n",
    "#Decoder\n",
    "decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(fusion_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "\n",
    "model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1077947,
     "status": "ok",
     "timestamp": 1544037626470,
     "user": {
      "displayName": "Shravankumar Shetty",
      "photoUrl": "https://lh3.googleusercontent.com/-jCxID2zpAz4/AAAAAAAAAAI/AAAAAAAAEKw/RMlX-iUrE1M/s64/photo.jpg",
      "userId": "00357225673176527270"
     },
     "user_tz": -330
    },
    "id": "B7NhlaG0v9sH",
    "outputId": "8893d4c1-bbae-4fe5-dea3-43775b699f19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "#Create embedding\n",
    "def create_inception_embedding(grayscaled_rgb):\n",
    "    grayscaled_rgb_resized = []\n",
    "    for i in grayscaled_rgb:\n",
    "        i = resize(i, (299, 299, 3), mode='constant')\n",
    "        grayscaled_rgb_resized.append(i)\n",
    "    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n",
    "    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n",
    "    with inception.graph.as_default():\n",
    "        embed = inception.predict(grayscaled_rgb_resized)\n",
    "    return embed\n",
    "\n",
    "# Image transformer\n",
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=20,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "#Generate training data\n",
    "batch_size = 20\n",
    "\n",
    "def image_a_b_gen(batch_size):\n",
    "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
    "        grayscaled_rgb = gray2rgb(rgb2gray(batch))\n",
    "        embed = create_inception_embedding(grayscaled_rgb)\n",
    "        lab_batch = rgb2lab(batch)\n",
    "        X_batch = lab_batch[:,:,:,0]\n",
    "        X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
    "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "        yield ([X_batch, create_inception_embedding(grayscaled_rgb)], Y_batch)\n",
    "\n",
    "#Train model      \n",
    "tensorboard = TensorBoard(log_dir=IMG_LOCATION + \"../output\")\n",
    "with tf.device('/gpu:0'):\n",
    "  model.compile(optimizer='adam', loss='mse')\n",
    "  model.fit_generator(image_a_b_gen(batch_size), epochs=30, steps_per_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cat6xJY9hUU9"
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "from google.colab import files\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    files.download('model.json')\n",
    "model.save_weights(\"color_tensorflow_real_mode.h5\")\n",
    "files.download('color_tensorflow_real_mode.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 419943,
     "status": "ok",
     "timestamp": 1544073644552,
     "user": {
      "displayName": "Shravankumar Shetty",
      "photoUrl": "https://lh3.googleusercontent.com/-jCxID2zpAz4/AAAAAAAAAAI/AAAAAAAAEKw/RMlX-iUrE1M/s64/photo.jpg",
      "userId": "00357225673176527270"
     },
     "user_tz": -330
    },
    "id": "pDeiiUgihfQe",
    "outputId": "27f8f939-8d2e-400f-91e6-45883192fe12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:132: UserWarning: /content/drive/My Drive/Colab_Notebooks/Drishti/Dataset/Train/../result/img_136.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:132: UserWarning: /content/drive/My Drive/Colab_Notebooks/Drishti/Dataset/Train/../result/img_274.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:132: UserWarning: /content/drive/My Drive/Colab_Notebooks/Drishti/Dataset/Train/../result/img_493.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n"
     ]
    }
   ],
   "source": [
    "#Make predictions on validation images\n",
    "# Change to '/data/images/Test/' to use all the 500 test images\n",
    "color_me = []\n",
    "for filename in os.listdir(IMG_LOCATION + '../Test'):\n",
    "    color_me.append(img_to_array(load_img(IMG_LOCATION + '../Test/'+filename)))\n",
    "color_me = np.array(color_me, dtype=float)\n",
    "color_me = 1.0/255*color_me\n",
    "color_me = gray2rgb(rgb2gray(color_me))\n",
    "color_me_embed = create_inception_embedding(color_me)\n",
    "color_me = rgb2lab(color_me)[:,:,:,0]\n",
    "color_me = color_me.reshape(color_me.shape+(1,))\n",
    "\n",
    "\n",
    "# Test model\n",
    "output = model.predict([color_me, color_me_embed])\n",
    "output = output * 128\n",
    "\n",
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "    cur = np.zeros((256, 256, 3))\n",
    "    cur[:,:,0] = color_me[i][:,:,0]\n",
    "    cur[:,:,1:] = output[i]\n",
    "    imsave(IMG_LOCATION + \"../result/img_\"+str(i)+\".png\", lab2rgb(cur))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "coloi",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
